<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <title>Billets d'humeur</title>
  <meta name="description" content="Vous cherchez à comprendre le point de vue constructiviste en sciences ou vous cherchez des musiques rares ou contemporaines, vous êtes à la bonne adresse!" />
  <link rel="shortcut icon" href="logo.ico" />
  <link href="style.css" rel="stylesheet" type="text/css" /> 
  <link href="https://fonts.googleapis.com/css?family=Josefin+Sans%7COswald%7COxygen%7CRaleway" rel="stylesheet">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
  <script src="js/jquery-1.10.2.js"></script>
  <script src="js/menus.js"></script>
  <script src="js/design.js"></script>
  <script src="js/gestionAudioVideo.js"></script>
  <script> 
    // Inclusion Header et Footer + class "active" (pour lien menu)
    $(function(){
      $(function(){
        $.ajax({
           url: "template/header.php",
           type: "POST",
           data: ({ROOT: './'}),
           success: function(data) {
             $("#header").html(data);
             $("#billetdhumeur").addClass("active"); /*a changer en fonction de la page*/
             update_design_when_header_loaded();
          }
        });
      });
      $("#miniMenus").load("template/miniMenus.php", { ROOT: './' }, mini_menus_after_loading);
      $("#footer").load("template/footer.php", { ROOT: './' }, update_design_footer);  
    });
  </script> 
</head>

<body id="site">

    <div>
        <!-- Inclusion header -->
        <div id="header"></div>

        <div id="miniMenus"></div>

        <div id="corps">

            <div id="contenuPrincipal">
                <h2>Billets d'humeur</h2>
                <h3>Textes d'opinions humoristiques souvent satiriques</h3>

                <nav class="filAriane">
                    <ul>
                        <li class="breadcrumbItem"><span>Vous êtes ici : </span> Musique</li>
                        <li class="breadcrumbItem  breadcrumIitem--current">
                          <a href="chroniques.html">Chroniques</a>
                        </li>
                        <li class="breadcrumbItem breadcrumIitem--current">Billets d'Humeur</li>
                    </ul>
                </nav>  
    <h2>Chroniques éparses : Informatique & Information.</h2>
  
  <div>Cette section, en construction permanente, présente des questions exotiques ou amusantes d'informatique théorique. </div>
  <p></p>
  
  <h3>1) Le problème des 12, 39, 120, ..., boules.</h3> 
  <p>Ce problème récréatif illustre la notion de bilan informationnel : on donne N boules, d'apparences identiques sauf que l'une d'entre elles est peut-être plus lourde ou plus légère que les autres. Combien de pesées sont nécessaires pour identifier l'intruse éventuelle ? On ne dispose que d'une balance à fléau, non graduée. Classiquement, on ne considère que le cas, N=12 qui se règle en k=3 pesées.</p>

<p>La théorie de l'information apporte une solution élégante au problème général.  L'information manquante se calcule sur base du logarithme (en base 2) du nombre des solutions possibles, supposées équiprobables, soit, lg(2N+1) bits (Dans le cas, N=12, cela représente lg25 = 4.64386 bits).</p>


<p>L'apport informationnel d'une pesée dépend du nombre de boules que l'on dépose dans chaque plateau. Si on dépose x boules de chaque côté, les probabilités que le fléau penche à gauche, reste en équilibre ou penche à droite valent respectivement :</p>

 <div><img src="annexes/boules/boules1.jpg" alt="" /></div>

<p>L'apport d'information se calcule sur base de la formule de Claude Shannon :</p>

 <div><img src="annexes/boules/boules2.jpg" alt="" /></div>

<p>
Cette fonction est maximum lorsque x=N/3 (soit x=4 dans l'exemple de 12 boules).</p>

<div><img src="annexes/boules/boules3.jpg" alt="" /></div>

<p>Cette pesée favorable apporte lg3 = 1.585 bits par pesée indépendante.</p>
<p> Vu que 3 x 1.585 = 4.75489 > 4.64386 (bits), rien ne semble s'opposer à ce qu'il existe une solution en k=3 pesées dans le cas N=12 (dont l'existence ne peut être établie qu'en la détaillant !).</p>

<p>La solution proposée par John Conway, l'un des mathématiciens les plus inventifs de sa génération, est particulièrement élégante. On détaille l'exemple classique k=3, N=12 mais la généralisation est immédiate, disponible en <a href="annexes/boules/boules.html">annexe</a> (<a href="annexes/boules/boules.nb">Notebook Mathematica</a>).</p>

<p> Quel que soit k, Conway travaille sur un alphabet de 3 lettres, G, D et E, observant qu'il permet de former 3<sup>k</sup> = 27 mots distincts de k=3 lettres. De cette liste, il enlève les mots constants, GGG, DDD et EEE,  ne retenant que ceux où le premier changement de lettre respecte l'un des schémas GD DE ou EG. Au bilan il reste 12 mots distincts qu'il associe à chacune des 12 boules :</p>


<p>GGD GDG GDD GDE DDE DEG DED DEE EGG EGD EGE EEG</p>


<p>Les trois pesées mettent en balance les boules suivantes :</p>

<table width="700" border="5" cellspacing="5" cellpadding="5">
  <tr>
    <td>1:</td>
    <td><span style="color:#F60">GGD GDG GDD G</span>DE</td>
    <td><span style="color:#F60">DDE DEG DED D</span>EE</td>
  </tr>
  <tr>
    <td>2:</td>
    <td>G<span style="color:#F60">GD EGG EGD EG</span>E</td>
    <td>G<span style="color:#F60">DG GDD GDE DD</span>C</td>
  </tr>
  <tr>
    <td>3:</td>
    <td>GD<span style="color:#F60">G DEG EGG EEG</span></td>
    <td>GG<span style="color:#F60">D GDD DED EGD</span></td>
  </tr>
</table>

 
  <div>où la i<sup>ième</sup> pesée place les boules codées par G en i<sup>ième</sup> position à gauche et celles codées par D en i<sup>ième</sup> position à droite.
    
    Chaque pesée fournit un résultat que l'on note, G, si le fléau penche à gauche, D, s'il penche à droite et, E, s'il reste en équilibre. Les trois lettres, prises dans cet ordre, forment un mot qui identifie la boule anormale (Il est alors facile de voir si elle est plus lourde ou plus légère). Si le mot trouvé est EEE, toutes les boules sont identiques. GGG et DDD n'apparaissent jamais.</div>


<p>La méthode de Conway se généralise immédiatement à un nombre plus grand de pesées (et de boules !). La pesée la plus porteuse d'information place x = N/3 boules dans chaque plateau (à condition que N soit divisible par 3 !), amenant lg3 = 1.585 bits. On serait alors tenté de raisonner ainsi : k pesées indépendantes apportent  k lg3 (bits) et il faut combler lg(2N+1) bits d'information manquante d'où k pesées devraient venir à bout du problème à N=(3<sup>k</sup>-1)/2 boules. C'est un peu vite dit car ce N-là n'est pas multiple de 3 d'où l'information apportée par chaque mesure est inférieure au maximum escompté, 1.585 bits. En fait, (3<sup>k</sup>-2)/2 n'est pas davantage multiple de 3, par contre N = (3<sup>k</sup>-3)/2 l'est. C'est la solution optimale cherchée et la construction de Conway continue de s'appliquer.</p>

 
<div><img src="annexes/boules/boules4.jpg" alt="" /></div>
 
<p>En résumé, k pesées résolvent le problème des (3<sup>k</sup>-3)/2 boules et inversement. En particulier, k (= 2,3,4,5, …) pesées suffisent tout juste pour régler le problème comportant 3, 12, 39, 120, …, boules. </p>

<p></p>
  
  <h3>2) Quelques exemples de programmes en langage Fractran.</h3> 
  <p>John Conway est encore à l'honneur grâce à l'un de ces joyaux dont il a le secret : Fractran. Il a publié l'essentiel de son travail, en 1987, dans l'ouvrage collectif "Open Problems in Communication and Computation (Springer Verlag)".  Ce résumé s'inspire de cette publication et de quelques essais isolés, parus dans des <a href="http://stigant.livejournal.com/9602.html" class="italique">forums</a>  spécialisés.</p>
  
  <p>Fractran est un langage un brin ésotérique mais universel au sens de Turing donc équivalent au modèle de la machine du même nom, qui incarne classiquement la notion de calcul.  On sait que le kit minimal d'instructions nécessaires à la programmtion de n'importe quelle fonction calculable  est ridiculement mince. On connait plusieurs modèles calculatoires formellement équivalents dont le plus simple est sans doute la machine à registres présentée par ailleurs sur ce site, à la rubrique Séminaires. Fractran est équivalent à la machine à registres grâce au fait que tout entier naturel possède une décomposition unique en facteurs premiers, les atomes de l'arithmétique. Ainsi l'entier, 600 = 2<sup>3</sup>3<sup>1</sup>5<sup>2</sup> peut être vu comme l'encodage  des entiers 3, 1 et 2 dans trois registres distincts. A partir de ces prémices, Conway a imaginé le langage suivant :</p>
  <p>- Tout algorithme applique un programme à un ensemble de données. Un programme Fractran est représenté par une suite, F, ordonnée et finie, de fractions rationnelles. Les données sont représentées par un entier, n. L'algorithme fonctionne itérativement comme suit :</p>
  
<p>- L'entier n est multiplié successivement par les fractions de la suite F jusqu'à tomber sur un entier. Lorsque celui-ci est trouvé, il prend la place de n et le processus des multiplications successives recommence. Le calcul s'interrompt lorsqu'aucun produit n'est trouvé entier : l'entier en cours est alors imprimé. Le lecteur vérifiera, à la main, que les programmes suivants effectuent les tâches algorithmiques annoncées. Il peut aussi se référer aux programmes joints en <a href="annexes/fractran/fractran.html">annexe</a> (<a href="annexes/fractran/fractran.nb">Notebook Mathematica</a>). Il notera qu'il est possible de proposer des progammes Fractran concis qui effectuent des tâches non triviales, une performance généralement interdite aux machines de Turing. Les plus  curieux chercheront d'autres exemples mais la recherche des programmes, F, requiert une certaine expertise.</p>

<div><i>6 programmes simples.</i></div>
<p>1) Addition de deux entiers.</p>
<p>Ce programme, sans doute le plus simple de tous, ne comporte qu'une seule instruction, F = {3/2}. Les entiers à additionner, x et y, sont encodés sous la forme, n = 2<sup>x</sup>3<sup>y</sup>. Les multiplications successives déroulent le programme comme suit, jusqu'à l'arrêt où le résultat s'affiche en exposant de 3 :</p>
<p>2<sup>x</sup>3<sup>y</sup> → 2<sup>x-1</sup>3<sup>y+1</sup> → 2<sup>x-2</sup>3<sup>y+2</sup> → ... → 3<sup>x+y</sup></p>
<p>On remarque que le même programme permet de transférer le contenu d'un registre vers un autre registre : 2<sup>x</sup> → ... → 3<sup>x</sup>. Quant au programme, F = {3<sup>a</sup>/2}, il calcule la fonction, y+ax selon le schéma : 2<sup>x</sup>3<sup>y</sup> → 3<sup>y+ax</sup>. </p>

<p>2) Multiplication de deux entiers.</p>
<p>Ce programme légèrement plus long, requiert 6 instructions, F = {455/33, 11/13, 1/11, 3/7, 11/2, 1/3}. Les entiers à multiplier, x et y, sont encodés sous la forme, n = 2<sup>x</sup>3<sup>y</sup> et le résultat s'affiche, au moment de l'arrêt, sous la forme d'une puissance de 5 :</p>
<p>2<sup>x</sup>3<sup>y</sup> → ... → 5<sup>xy</sup></p>

<p>3) Division entière.</p>
<p>Ce programme utilise 8 instructions, F = {91/66, 11/13, 1/33, 85/11, 57/119, 17/19, 11/17, 1/3}. Les entiers à diviser, x et y, sont encodés sous la forme, n = 2<sup>x</sup>3<sup>y</sup>11. Au terme du calcul,  le quotient (entier) s'affiche en exposant de 5 et le reste (entier) s'affiche en exposant de 7 :</p>
<p>2<sup>x</sup>3<sup>y</sup>11 → ... → 5<sup>Integer[x/y]</sup> 7<sup>Mod[x,y]</sup></p>

<p>4) PGCD.</p>
<p>Ce programme utilise 11 instructions, F = {22/19, 21/23, 51/55, 11/17, 26/35, 7/13, 1/11, 1/7, 5/6, 23/3, 19/2}. Les entiers donnés, x et y, sont encodés sous la forme, n = 2<sup>x</sup>3<sup>y</sup>. Au terme du calcul, le PGCD s'affiche en exposant de 5 :</p>
<p>2<sup>x</sup>3<sup>y</sup> → ... → 5<sup>PGCD[x,y]</sup></p>



<p>5) Déterminer le plus petit parmi deux entiers est possible sur base de 3 instructions, F = {5/6, 1/2, 1/3} :</p>
<p>2<sup>x</sup>3<sup>y</sup> → ... → 5<sup>Min[x,y]</sup></p>

<p>5bis) Un programme similaire, F = {5/6, 5/2, 5/3} calcule le plus grand parmi deux entiers :</p>
<p>2<sup>x</sup>3<sup>y</sup> → ... → 5<sup>Max[x,y]</sup></p>

<p>6) L'échange du contenu de deux registres est possible sur base de 7 instructions, F = {55/14, 7/11, 13/7, 34/39, 13/17, 1/13, 3/5} :</p>
<p>2<sup>x</sup>3<sup>y</sup>7 → ... → 2<sup>y</sup>3<sup>x</sup></p>

<div><i>Calculs de fonctions.</i></div>
<p>1) Le programme, F = {13/11, 133/85, 17/19, 23/17, 1015/69, 23/29, 31/23, 111/217, 31/37, 
 13/31, 17/26, 33/2, 1/13, 1/5}, calcule n'importe quel élément de la suite de Fibonacci, {0, 1, 1, 2, 3, 5, 8, ...}, selon le schéma :</p>

<p>2<sup>x</sup> → ... → 3<sup>fib[x]</sup></p>

<p>2) Le programme, F = {115/38, 19/23, 17/19, 4147/51, 17/29, 31/17, 259/155, 41/31, 129/481,
  37/43, 17/37, 47/533, 41/47, 53/41, 177/583, 53/59, 61/53, 67/427, 
 1/61, 355/469, 67/71, 17/67, 57/2}, calcule la factorielle, x!, d'un entier donné :</p>
 
 <p>2<sup>x</sup> → ... → 3<sup>x!</sup></p>



<div><i>Programme universel.</i></div>
<p>Les programmes qui précèdent sont équivalents à autant de machines de Turing dédicacées au calcul d'une fonction particulière. Il est possible de concevoir un programme unique, capable de calculer toute fonction calculable (jouant, en Fractran, le rôle d'une machine de Turing universelle). Ce programme s'écrit :</p> 

<p>F = {583/559, 629/551, 437/527, 82/517, 615/329, 371/129, 1/115, 53/86, 43/53, 23/47, 341/46, 41/43, 47/41, 29/37, 37/31, 37/31, 299/29, 47/23, 161/15, 527/19, 159/7, 1/17, 1/13, 1/3}</p>
<p>L'ensemble des fonctions calculables par programmes étant dénombrable, il peut être indicé par un paramètre entier, k. On a que si f<sub>k</sub>(n) = m, alors le programme fournit : k 2<sup>2^n</sup> → ... → 2<sup>2^m</sup>.</p>
<p> L'article fondateur de Conway présente le début du catalogue des fonctions, f<sub>k</sub>(n). Sans grande surprise, les premières fonctions sont largement triviales : f<sub>1</sub>(n) = n est l'identité, f<sub>256</sub>(n) n'est définie que pour n=3 (f<sub>256</sub>(3)=4) et f<sub>2268945</sub>(n) = n+1. </p>
<div><i>Algorithmes compte-gouttes.</i></div>
<p>L'universalité calculatoire de Fractran garantit qu'il est capable d'énumérer des listes, finies ou infinies, de nombres reliés par une propriété commune :</p>
<p>1) Suite de Collatz.</p>
<p>Pour rappel, cette suite est construite itérativement au départ de n'importe quel entier, n, faisant suivre tout entier, m, de m/2 si m est pair et de (3m+1)/2 sinon. On a conjecturé qu'elle retombe invariablement à la valeur, m=1.  Le programme suivant, dû à Kenneth Monks, F = {1/11, 136/15, 5/17, 4/5, 26/21, 7/13, 1/7, 33/4, 5/2, 7/1}, appliqué à 2<sup>n</sup> calcule une suite dont on ne retient que les puissances de 2 : les exposants sont les termes de la suite démarrant à n. </p>


<p>2) Suite des nombres premiers.</p>
<p>Le programme, F = {17/91, 78/85, 19/51, 23/38, 29/33, 77/29, 95/23, 77/19, 1/17, 11/13, 13/11, 15/2, 1/7, 55/1}, appliqué à, n = 2,  passe successivement, sans jamais s'arrêter, par toutes les puissances de 2, 2<sup>p</sup> où p est premier. Conway a publié une description abrégée du fonctionnement de l'algorithme sur ce <a href="http://www.mathematik.uni-bielefeld.de/~sillke/NEWS/fractran">forum</a>. </p>

<div><i>Décimales de pi.</i></div>

<p>Le programme, F = {365/46, 29/161, 79/575, 679/451, 3159/413, 83/407, 473/371, 638/355, 434/335, 89/235, 17/209, 79/122, 31/183, 41/115, 517/189, 111/83, 305/79, 23/73, 73/71, 61/67, 37/61, 19/59, 89/57, 41/53, 833/47, 53/43, 86/41, 13/38, 23/37, 67/31, 71/29, 83/19, 475/17, 59/13, 41/291, 1/7, 1/11, 1/1024, 1/97, 89/1},  basé sur la formule de Wallis, est censé agir sur la donnée 2<sup>n</sup> pour produire 2<sup>pi[n]</sup> comme première puissance de 2, où pi[n] est la n<sup>ème</sup> décimale de pi. Ce programme ne fonctionne malheureusement pas,  à cause d'une erreur, jamais corrigée (avis aux amateurs !), probablement au niveau de l'encodage de la donnée, n. Même s'il fonctionnait, il serait d'une lenteur désespérante.</p>


<p></p>
  
  <h3>3) Une variante aisée du tour de Cheney.</h3> 
<p>Attribué à William Fitch Cheney (1831-1879), ce tour de cartes refait régulièrement surface dans les magazines spécialisés. Jean-Paul Delahaye a fait une synthèse des variantes existantes dans une de ses chroniques mensuelles de la revue, Pour la Science (02/2006). Exempt de tout subterfuge, ce tour n'a rien de magique : il maximise le transfert d'information lors de l'échange d'un nombre donné de cartes discernables entre deux partenaires, dénommés Maurice, le magicien, et Alice, son assistante (Le tour fonctionne pareillement si Marie est la magicienne et Albert l'assistant). Quelle que soit la variante, le jeu traditionnel de 52 cartes est remplacé par un jeu de, N, cartes numérotées de 0 à N-1. Celle que nous proposons ici utilise N = n! + n cartes et elle présente l'intérêt de réduire l'intervention mathématique à sa plus simple expression.</p>


<div><i>La numération factoradique.</i></div>
<p>En arithmétique, l'encodage des entiers se fait habituellement dans une base fixe, b, selon les puissances de b et les chiffres autorisés vont de 0 à b-1. La base 10 est habituelle (chiffres de 0 à 9) mais la base 2 (chiffres binaires 0 et 1) est également d'un usage fréquent. D'autres systèmes de numération existent cependant qui se révèlent intéressants dans certains cas précis. Tel est le cas du système factoradique. Tout entier naturel, x, peut être décomposé d'une seule façon sous la forme, x = c<sub>m</sub>m! + c<sub>m-1</sub>(m-1)! + ... + c<sub>1</sub>1!, où les chiffres, c<sub>j</sub>, vont de 0 à j. Par exemple, 20 = 3 3! + 1 2! + 0 1!. Nous noterons la succession des chiffres entre crochets comme dans l'exemple,  20 = [3,1,0]. Ce système exotique autorise une numérotation simple des permutations de n symboles initialement rangés dans l'ordre naturel, par exemple (si n=4), a < b < c < d.</p>

<p> Il existe 4! = 24 permutations distinctes des symboles, a, b, c, et d. Les voici rangées dans l'ordre lexicographique et numérotées de 0 à 23 :</p>

<table width="700" border="5" cellspacing="5" cellpadding="5">
  <tr>
    <td>( a b c d )0</td>
    <td>( a b d c )1</td>
    <td>( a c b d )2</td>
    <td>( a c d b )3</td>
    <td>( a d b c )4</td>
    <td>( a d c b )5</td>
  </tr>
  <tr>
    <td>( b a c d )6</td>
    <td>( b a d c )7</td>
    <td>( b c a d )8</td>
    <td>( b c d a )9</td>
    <td>( b d a c )10</td>
    <td>( b d c a )11</td>
  </tr>
  <tr>
    <td>( c a b d )12</td>
    <td>( c a d b )13</td>
    <td>( c b a d )14</td>
    <td>( c b d a )15</td>
    <td>( c d a b )16</td>
    <td>( c d b a )17</td>
  </tr>
  <tr>
    <td>( d a b c )18</td>
    <td>( d a c b )19</td>
    <td>( d b a c )20</td>
    <td>( d b c a )21</td>
    <td>( d c a b )22</td>
    <td>( d c b a )23</td>
  </tr>
</table>


<p>La numération factoradique permet de retrouver rapidement quelle permutation occupe le k<sup>ième</sup> rang, dans ce tableau, et inversement quel rang y occupe une permutation donnée :</p>


<p>- Pour trouver la permutation de rang, k, il suffit de décomposer l'entier, k, en numération factoradique, comme dans l'exemple, k = 20 = [3,1,0]. La 20<sup>ième</sup> permutation de la liste ( a b c d ) s'obtient en sélectionnnant, dans l'ordre, le symbole de rang 3 (d) - attention le rang le plus à gauche se note 0 -, puis de rang 1 parmi ceux qui restent (b), puis celui de rang 0 parmi ceux qui restent (a), enfin celui qui reste seul (c). Au bilan, la 20<sup>ième</sup> permutation de ( a b c d ) se note, ( d b a c ).</p>

<p>- Pour trouver l'indice d'une permutation donnée, par exemple ( d b a c ), il suffit de compter (dans l'ordre !) combien d'éléments suivent le 1<sup>er</sup> symbole (d) et lui sont inférieurs, idem pour le 2<sup>ième</sup> symbole (b) et idem pour le 3<sup>ième</sup>, a. On trouve [3,1,0] qui sont les chiffres factoradiques de l'indice cherché, soit, k = 3 3! + 1 2! + 0 1! = 20. On note que, dans ce système, ( a b c d ) porte le numéro 0 et que (d c b a ) porte le numéro 4!-1 = 23. Le lecteur vérifiera la pertinence du tableau ci-dessus.</p>


<div><i>Le tour des 9, 28, 125, 726, ..., cartes.</i></div>
<p>Nous l'illustrons dans le cas n=5. n! + n  = 125 cartes, portant chacune un numéro différent, de 0 à 124, sont soigneusement mélangées. Alice tire n+1 = 6 cartes au hasard, soit (3 27 51 52 80 101) et elle en détache une quelconque, appelons-la x = 52, qu'elle dissimule. Elle tend à Maurice les 5 cartes restantes judicieusement empilées dans un ordre à définir. C'est le coeur de la transmission d'information : Maurice sait que les cartes étaient initalement en nombre 125 et que la carte mystère ne peut pas être une de celles qu'Alice lui tend. Au bilan il reste 120 possibilités. Il faut donc qu'Alice dispose de 120 éléments distincts d'information. Or 120 = 5! est précisément égal au nombre des permutations des 5 cartes qui constituent la pile transmise par Alice à Maurice. Il suffit donc que l'empilement corresponde au numéro d'ordre de la permutation utilisée.</p>

<p><i>L'encodage.</i></p>
<p>La carte mystère porte le numéro, x = 52. Toutefois 52 n'est pas nécessairement l'entier qu'il convient de faire passer à Maurice, c'est en fait, x - y, où y = 3 désigne le nombre de cartes montrées à Maurice et de rang inférieur à x. C'est donc le nombre, 52-3 = 49, qu'Alice doit encoder en numération factoradique. En appliquant l'algorithme ci-dessus, elle trouve 49 = [2 0 0 1], ce qui correspond à la permutation (51 3 27 101 80). C'est dans cet ordre qu'Alice tend les cartes à Maurice.</p>


<p><i>Le décodage.</i></p>
<p>La tâche de Maurice est plus facile (C'est d'ailleurs pour cela que le magicien est l'homme !). Maurice reçoit un paquet de n = 5 cartes qui se présentent dans l'ordre (51 3 27 101 80). Il lui est facile de voir que cette permutation porte le numéro d'ordre, z = 49.  Cet entier, z, est presque le numéro, x, cherché : il faut encore passer les cartes en revue (dans l'ordre !) en ajoutant 1 à z tant qu'il reste dans la pile des nombres plus petits que z réactualisé. Le résultat final désigne le rang, x, de la carte mystère. On trouve successivement : z = 49, 50 (à cause de la présence de 3), 51 (à cause de la présence de 27) et finalement 52 (à cause de la présence de 51). La carte mystère porte le numéro 52.</p> 

<div><img src="annexes/magie/magie2.jpg" alt="" /></div>

<p></p>
  
  <h3>4) Devinez l'entier !</h3> 
 <p>Ce jeu un brin académique, entre deux partenaires nommés A et B, offre l'occasion de réfléchir à quelques concepts liés aux théories des probabilités et de l'information. Il se pose informellement de la manière suivante :</p> 
 <p>A sélectionne "au hasard" un entier positif, n, à charge pour B de le deviner le plus rapidement possible. Pour progresser dans sa recherche, B ne peut poser à A que des questions binaires de son choix, auxquelles B répond honnêtement, par oui ou par non.</p> 
 
 <p>Présenté en ces termes, le problème est mal posé car son énoncé est imprécis sur un point essentiel : il ne dit pas ce que signifie, pour A, la sélection d'un entier au hasard. On pourrait penser à la méthode suivante : A enferme des boules numérotées dans une urne, agite celle-ci consciencieusement et puise une boule donc un entier au hasard. Cette manière de faire n'est recevable que si le nombre des boules est fini, autrement dit si l'intervalle des entiers disponibles pour le tirage aléatoire est lui aussi fini, disons [1, N]. Encore faut-il préciser si l'urne contient exactement N boules numérotées chacune de 1 à N sans répétion ou si, au contraire, certains numéros sont présents plusieurs fois voire d'autres éventuellement absents (Dans la suite, on a remplacé l'urne et les boules par une cible circulaire et un jeu de fléchettes). On formalise ces exigences de la manière suivante : il faut que A informe B de</p>
 <p>- l'intervalle dans lequel il travaille, [1, N] s'il est fini, et [1, Infini], dans le cas contraire et de</p>
 <p>- la densité distributionnelle, g(n), des probabilités qu'il utilise, favorisant éventuellement certains entiers par rapport à d'autres.</p>
 
 
 <p>1) Le cas particulier suivant, classique et inoffensif, considère la densité homogène sur l'intervalle fini, [1, N] : </p>
<div><img src="annexes/entier/entier.jpg" alt="" /></div>
 <div><img src="annexes/entier/entier12.jpg" alt="" /></div>
 <div class="grandelignevide"></div> <div class="grandelignevide"></div>
 
 <p> L'information manquante vaut ℓg(N) bits (formule de Shannon), ce qui autorise à penser qu'une stratégie existe, pour B, lui permettant de deviner l'entier inconnu en Ceil[ℓg(N)] questions binaires. Cette stratégie porte le nom de dichotomie binaire; on la rappelle dans le cas, N=32=2<sup>5</sup>, où 5 questions  devraient suffire. A chaque étape, on réduit l'intervalle possible [a, b] de moitié, en posant la question, n > (a+b-1)/2 ? Voyons cela sur l'exemple, n = 25 :</p>
 <p>- 1<sup>ère</sup> question : n>16 ? Réponse : OUI = 1 (Il reste les entiers allant de 17 à 32)</p>
  <p>- 2<sup>ème</sup> question : n>24 ? Réponse : OUI = 1 (Il reste les entiers allant de 25 à 32)</p>
   <p>- 3<sup>ème</sup> question : n>28 ? Réponse : NON = 0 (Il reste les entiers allant de 25 à 28)</p>
    <p>- 4<sup>ème</sup> question : n>26 ? Réponse : NON = 0 (Il reste les entiers 25 et 26)</p>
     <p>- 5<sup>ème</sup> question : n=25 ? Réponse : OUI = 1 (n = 25, notez que 25 se note 11001 en binaire)</p>
  
<p>L'exemple N=32 fonctionne particulièrement bien parce que 32 est une puissance de 2 donc l'information manquante est entière dans ce cas (elle vaut 5 bits). Lorsque N n'est pas une puissance de 2, la dichotomie binaire demeure la stratégie optimale avec la nuance suivante. Supposons  N=17, l'information manquante  vaut, à présent, ℓg(N)=4.087469 bits. La stratégie binaire précédente devine certainement l'entier, n, en 5 questions (Après tout, qui peut le plus peut le moins) mais elle fait  mieux, en moyenne, soit en 71/17 = 4.17647 questions binaires, ce qui nous rapproche de la limite de Shannon. Il suffit, pour le voir, d'examiner tous les cas de figures et de se rendre compte que 4 questions suffisent dans 14 cas sur 17 tandis qu'il en faut 5 dans 3 cas sur 17 seulement.</p>




<p>2) Le cas infini est nettement plus délicat. Commençons par remarquer qu'il n'est plus possible, dans ce cas, de considérer que tous les entiers sont équiprobables : la fonction de distribution, g(n), ne serait pas normalisable à l'unité. Une procédure effective permettant à A de sélectionner au hasard  un entier arbitrairement grand n'est envisageable que selon un hasard non uniforme qui pénalise les grands entiers. Plus formellement, la fonction de distribution doit être suffisamment décroissante, lorsque n s'éloigne à l'infini, afin de garantir la normalisation de g(n). Une décroissance selon la loi, g(n)=1/n, ne suffit pas car la série harmonique diverge, par contre, une décroissance selon la loi, g(n)=1/n<sup>2</sup>, convient certainement. Etudions ce cas :
<div><img src="annexes/entier/entier1.jpg" alt="" /></div>

<div><img src="annexes/entier/entier10.jpg" alt="" /></div>


<div class="grandelignevide"></div>
<div class="grandelignevide"></div> <div class="grandelignevide"></div>


<p>L'information manquante vaut dans ce cas précis (formule de Shannon) :</p>



<div><img src="annexes/entier/entier2.jpg" alt="" /></div>

<p>Il ne faudrait pas en conclure que 3 questions binaires devraient suffire à B pour découvrir, à tous coups, l'entier inconnu, d'ailleurs cela n'aurait aucun sens : tous les entiers étant possibles sans restriction de taille, il ne faut pas espérer deviner tous les cas en un nombre fini de questions. Ce que la formule de Shannon laisse espérer, dans le cas infini, est différent, à savoir qu'il existe une stratégie qui, en moyenne, devine l'entier caché en approximativement 2.4 questions binaires. Autrement dit, il se fera certainement que 10 ou 20 questions s'avèrent nécessaires mais ces cas coûteux seront rares.  Cette stratégie optimale moyenne existe effectivement et elle est à nouveau basée sur la dichotomie équitable que voici dans le détail.</p>

<p> Dans la série infinie suivante, la partition la plus équitable se note :</p>
<div><img src="annexes/entier/entier3.jpg" alt="" /></div>
<p> d'où la 1<sup>ère</sup> question posée par B :</p>

<p>- 1<sup>ère</sup> question : n>1 ? Une réponse négative ne laisse la place qu'à une seule valeur pour n, soit n=1. Dans ce cas favorable, une seule question a suffit.</p>

<p>Si la réponse à la première question est positive, il convient de poursuivre en partitionnant équitablement  le reste de la série infinie. On trouve :</p>
<div><img src="annexes/entier/entier4.jpg" alt="" /></div><p> d'où la 2<sup>ème</sup> question posée par B :</p>


  <p>- 2<sup>ème</sup> question : n>3 ?  Une réponse négative ne laisse la place qu'aux deux valeurs, n=2 et n=3, d'où une question supplémentaire suffit pour trancher. Au bilan, dans ce cas favorable, 3 questions ont suffit sinon il convient de poursuivre la recherche avec la partition suivante :</p>
  
 <div><img src="annexes/entier/entier5.jpg" alt="" /></div>

<p>d'où la 3<sup>ème</sup> question posée par B :</p>


  <p>- 3<sup>ème</sup> question : n>7 ?  Une réponse négative  laisse la place aux quatre valeurs, n=4, n=5, n=6 et n=7, d'où deux questions supplémentaires suffisent pour trancher.  Au bilan, dans ce cas favorable, 5 questions ont suffit sinon il convient de poursuivre la recherche avec la partition suivante.</p>
   
<p>Poursuivant la manoeuvre avec les restes successifs, on trouve que la k<sup>ième</sup> question revêt la forme simple :</p>
<p>- k<sup>ème</sup> question : n>2<sup>k</sup>-1 ?  Une réponse négative ne laisse la place qu'à 2<sup>k-1</sup> valeurs pour n, allant de n=2<sup>k-1</sup> à n=2<sup>k</sup>-1, inclus, d'où k-1 questions supplémentaires suffisent pour trancher; au bilan, cela fait 2k-1 questions dans ce cas favorable.</p>

<p><i>Note : cette affirmation repose sur la double inégalité remarquable, donnée sans démonstration :</i></p>
<div><img src="annexes/entier/entier6.jpg" alt="" /></div>


<p>Au bilan, le nombre moyen de questions binaires que B doit poser se calcule comme suit :</p>

<div><img src="annexes/entier/entier7.jpg" alt="" /></div>
<p>Il n'y a pas lieu de s'étonner que ce nombre soit légèrement supérieur à la valeur théorique de Shannon (2.36529) : les partitions opérées successivement  ne sont qu'approximativement égales et cela a un prix bien connu en théorie de l'information.</p> 


<p>On le voit, la meilleure stratégie, sans être  particulièrement imaginative, est plutôt efficace puisqu'elle règle le problème en 2.45 questions, en moyenne. Cette belle performance résulte du fait qu'on a utilisé une stratégie tenant compte de la  décroissance de, g(n), qui oblige A à choisir plus fréquemment des entiers de petite taille. Notez que la stratégie naïve consistant à poser comme k<sup>ième</sup> question, "L'entier cherché vaut-il k ?" est loin d'être optimale, le temps moyen devenant infini : c'est la conséquence de la divergence de la série harmonique.</p>


<p>3) Posons à présent que A veuille compliquer la tâche de B au maximum : il y parvient en utilisant une distribution, g(n), dont la normalisation repose sur une série convergeant vers 1 le plus lentement possible. Il est remarquable qu'une telle distribution - dite universelle - existe, qui se situe  à la limite de la convergence et de la divergence. Elle est basée sur une suite de résultats analytiques concernant les séries infinies, que l'on rappelle :</p>

<p>- Les séries infinies suivantes divergent toutes mais de plus en plus lentement :</p>
<div><img src="annexes/entier/diverge.jpg" alt="" /></div>

<p>Par contre, les séries infinies suivantes convergent toutes mais de plus en plus lentement :</p>
<div><img src="annexes/entier/converge.jpg" alt="" /></div>

<p>- On en déduit que la série infinie suivante se situe à la frontière qui sépare la convergence de la divergence :</p>
<div><img src="annexes/entier/frontiere.jpg" alt="" /></div>

<p>Voyons le rapport que cette série entretient avec le tirage aléatoire d'un entier non borné. Commençons par noter que ce tirage ne peut reposer sur le principe naïf suivant : tout entier positif possédant une traduction binaire en termes de 0 et de 1, on lancerait une pièce de monnaie et la suite des tirages successifs pile (=1) ou face (=0) construirait (de droite à gauche) l'entier désiré. Cette procédure ne fonctionne pas pour la raison évidente qu'elle ne comporte aucune instruction d'arrêt : après avoir tiré, disons 10011, comment savoir s'il faut s'arrêter et accepter l'entier correspondant (19) ou continuer à lancer la pièce? Préfixer l'écriture binaire de 10011 par une étiquette binaire, 101, qui annoncerait sa longueur (5) ne convient pas davantage car rien dans la succession des chiffres tirés, 101 10011, ne distinguerait la fin de l'étiquette du début du nombre proprement dit. La solution à ce case-tête est l'étiquetage répétitif  : on préfixe bien la représentation binaire de n=10011 par une étiquette, 101, qui annonce sa longueur (5) puis on fait de même avec une deuxième étiquette, 11, qui annonce la longueur (3) de la première et ainsi de suite jusqu'à tomber sur une étiquette de longueur 2 (=10) ou 3 (=11), ce qui ne peut manquer de se produire. On termine la procédure en préfixant le tout par autant de 0 que le nombre total d'étiquettes consommées, ce qui donnerait dans notre exemple, 00 10 101 10011, où les espaces servent seulement à faciliter votre lecture. La méthode qui vient d'être exposée est presque optimale mais il est possible de faire les économies suivantes : on peut enlever le 1 initial de l'écriture binaire du nombre n et de toutes les étiquettes (sauf la dernière, pour des questions de décodabilité). C'est la conséquence naturelle du fait qu'un entier binaire positif commence toujours par un 1 non significatif. Au bilan, le code de l'entier n=19 se note 00 10 01 0011.  La procédure peut paraître coûteuse aux petites valeurs de n mais, asymptotiquement, on verra qu'il n'y a pas moyen de faire mieux. On trouvera, en <a href="annexes/entier/entier.html">annexe</a>, le détail des procédures décrites (<a href="annexes/entier/entier.nb">Notebook Mathematica</a>).</p>

<p>Le lecteur vérifiera, sur quelques valeurs de n, que la procédure fonctionne sur tous les entiers supérieurs à 3. Les entiers 1, 2 et 3 sont encodés séparément en commençant par un 1, ce qui empêche toute confusion. Au bilan, on trouve la liste suivante des codes préfixes universels des entiers positifs :</p>


<p>S<sub>pref</sub> = {</p>
<p>s<sub>1</sub> ≡ 10, s<sub>2</sub> ≡ 110, s<sub>3</sub> ≡ 111, s<sub>4</sub> ≡ 01000, s<sub>5</sub> ≡ 01001, s<sub>6</sub> ≡ 01010, s<sub>7</sub> ≡ 01011,</p>

<p> s<sub>8</sub> ≡ 011000, s<sub>9</sub> ≡ 011001, s<sub>10</sub> ≡ 011010, s<sub>11</sub> ≡ 011011, s<sub>12</sub> ≡ 011100, s<sub>13</sub> ≡ 011101,
 s<sub>14</sub> ≡ 011110, s<sub>15</sub> ≡ 011111,</p>
 <p> s<sub>16</sub> ≡ 0010000000, s<sub>17</sub> ≡ 0010000001,..., s<sub>31</sub> ≡ 0010011111,</p>
 <p> s<sub>32</sub> ≡ 00100100000, ..., s<sub>63</sub> ≡ 00100111111,</p>
<p> ... }</p>

<p>La suite, S, est affichée de telle façon que sa structure numérique devienne apparente : elle contient 1 code de longueur 2, 2 codes de longueur 3, 4 codes de longueur 5 et plus généralement 2<sup>k</sup> codes de longueur ℓ(k), où la suite ℓ(k), croît comme (k = 0, 1, 2, 3, ...) :</p>

<p> ℓ(k) = {2,3,5,6,10,11,12,13,15,16,17,18,19,20,21,22,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,44,…}.</p>

<p> La suite, S, possède trois propriétés remarquables et essentielles pour le but poursuivi :</p>
<div><img src="annexes/entier/ldek.jpg" alt="" /></div>
<p>- Les longueurs de codes, ℓ(k), croissent asymptotiquement comme : ℓ(k) = k + ℓg(k) + ℓg(ℓg(k)) + ℓg(ℓg(ℓg(k))) + ... . C'est la conséquence naturelle du fait que chaque étiquette allonge le code de n d'une valeur égale au logarithme de l'étiquette précédente, la première étiquette l'allongeant du logarithme de n.</p>
<p>- La suite S est préfixe, ce qui signifie qu'aucun code d'entier n'est préfixe d'un autre code. C'est cette propriété qui justifie l'arrêt des tirages aléatoires dès qu'un terme de la suite est rencontré; il ne servirait, en effet, à rien de poursuivre.</p>
<p>- La suite S est complète, ce qui signifie que tout tirage aléatoire est assuré de se terminer sur un code faisant partie de la suite.</p>

<p>On montre, en théorie de l'information qu'un code préfixe et complet satisfait l'égalité de Kraft :</p>

<div><img src="annexes/entier/entier8.jpg" alt="" /></div>

<p>On peut vérifier directement ce résultat en regroupant astucieusement les termes de cette série, de n=2<sup>k</sup> à n=2<sup>2^k</sup>
</sup>-1 : les probabilités cumulées valent exactement 2<sup>-k</sup>, livrant une progression géométrique de raison, 1/2, convergent vers 1.</p>

<p>La stratégie optimale que B doit suivre se dégage à présent sur base d'une dichotomie binaire :</p>

<p>- 1<sup>ère</sup> question : n>3 ?  Une réponse négative laisse la place aux trois valeurs, n=1, n=2 et n=3, d'où deux questions supplémentaires suffisent certainement pour trancher.  Au bilan, dans ce cas favorable, 3 questions ont suffit sinon il convient de poursuivre la recherche avec la partition suivante.</p>

<p>- 2<sup>ème</sup> question : n>15 ?  Une réponse négative laisse la place aux douze valeurs, de n=4 à n=15, d'où quatre questions supplémentaires suffisent certainement pour trancher.  Au bilan, dans ce cas favorable, 6 questions ont suffit sinon il convient de poursuivre la recherche avec la partition suivante.</p>

<p>- 3<sup>ème</sup> question : n>65535 ?  Une réponse négative laisse la place aux 65520 valeurs, de n=16 à n=65535, d'où quatre questions supplémentaires suffisent certainement pour trancher.  Au bilan, dans ce cas favorable, 6 questions ont suffit sinon il convient de poursuivre la recherche avec la partition suivante.</p>
   
<p>Poursuivant la manoeuvre avec les restes successifs, on trouve que la k<sup>ième</sup> question (k>1) revêt la forme simple :</p>
<p>- k<sup>ème</sup> question : n>2^2^...<sub>k fois</sub>^2 - 1 ?  Une réponse négative "ne laisse la place qu'aux" valeurs de n, allant de n = 2^2^...<sub>(k-1) fois</sub>^2 à n = 2^2^...<sub>k fois</sub>^2-1, inclus, d'où de l'ordre de 2^2^...<sub>(k-1) fois</sub>^2 questions (!) suffisent pour trancher ce cas "favorable".</p>


<div><img src="annexes/entier/entier11.jpg" alt="" /></div>


<p>Vu que 2<sup>-ℓ(code[n])</sup> vaut précisément la probabilité de tirer au sort le code de n, on voit que l'égalité de Kraft remplit la condition de normalisation pour la densité de probabilité, g(n)=2<sup>-ℓ(code[n])</sup>.</p>


<p>En adoptant cette distribution, A est assuré de compliquer au maximum la tâche de B précisément parce que c'est la distribution la plus lentement décroissante parmi toutes celles qui sont envisageables. Le fait que la conditon de normalisation se situe à l'extrême limite de la convergence a une conséquence dramatique pour B : le nombre moyen de questions binaires tend vers l'infini. Autrement dit, B ne peut accepter aucun pari proposé par A sans être assuré de se ruiner, à terme.</p>


<p>Une dernière remarque : lorsque B n'est pas informé de la loi, g(n), adoptée par A, il est contraint de faire comme si c'était la distribution universelle. Procéder autrement équivaudrait à introduire un élément d'information parasite de nature à privilégier abusivement les petits entiers. La seule attitude prudente, qui ne présuppose rien d'inconnu, consiste à adopter la loi g(n) la moins porteuse d'information, celle qui décroît asymptotiquement le plus lentement possible sans compromettre la normalisation. Cette loi c'est la distribution universelle ou toute autre distribution asymptotiquement équivalente.</p>


<p></p>
  
  <h3>5) Fonctions de Walsh et compression avec perte.</h3> 
  <p>Autant l'analyse de Fourier (discrète) des signaux (digitaux) est connue autant celle de Walsh l'est peu. Le principe de base est similaire : il s'agit de trouver un ensemble orthogonal complet de fonctions permettant de développer n'importe quelle suite (digitale), de longueur 2<sup>s</sup> (s entier positif), en séries des fonctions de base. Alors que l'analyse de Fourier recourt à des fonctions de base trigonométriques, héritées de l'analyse infinitésimale, l'analyse de Walsh respecte le créneau binaire : ses fonctions de base ne prennent que deux valeurs, usuellement -1 et +1, pour des raisons de symétrie.</p>
  
  <p>Il y a mille façons d'introduire les fonctions de Walsh mais l'approche récursive de Hadamard semble la plus simple.  On commence par définir la suite des matrices de Hadamard 2<sup>s</sup>x2<sup>s</sup>, pour s = 0, 1, 2, …, comme suit :</p>

<div><img src="annexes/walsh/walsh1.jpg" alt="" /></div>
 <p>Voici deux matrices de Hadamard, de tailles raisonnables (respectivement s=3 et s=4) :</p>
<div><img src="annexes/walsh/walsh2.jpg" alt="" /></div>

<div class="grandelignevide"></div><div class="grandelignevide"></div>
<p>Pour une valeur donnée de s, les fonctions de Walsh sont définies par les vecteurs lignes (ou colonnes car les matrices de Hadamard sont symétriques) de H<sub>s</sub>.  Voici les graphes de ces fonctions de Walsh dans les deux cas pris en exemple :</p>
<div><img src="annexes/walsh/walsh3.jpg" alt="" /><div class="legende">Les 8 fonctions-1D de Walsh (s = 3)</div></div>

<div><img src="annexes/walsh/walsh4.jpg" alt="" /><div class="legende">Les 16 fonctions-1D de Walsh (s = 4)</div></div>

<p>La méthode de Hadamard énumère les 2<sup>s</sup> fonctions de Walsh, W<sub>s,i</sub> (i = 1, 2, ..., 2<sup>s</sup>), dans un ordre qui n'est pas nécessairement celui qui prévaut dans d'autres approches mais, au bilan, elles sont toutes bien présentes. Toutes sont orthogonales, au sens du produit scalaire habituel, et le carré de leur norme vaut 2<sup>s</sup>. Autrement dit, les fonctions, 2<sup>-s/2</sup>W<sub>s,i</sub> forment un ensemble orthogonormé qui est de plus complet : toute fonction, V, étagée sur l'ensemble {-1, +1}, par exemple la fonction {1,1,1,1,1,1,-1,-1} (s=3), est décomposable en termes de fonctions de Walsh, W<sub>3,i</sub>, et les coefficients du développement sont donnés par les produits scalaires, V.W<sub>3,i</sub>. Cela résulte de l'identité :</p>

<p>(2<sup>-s/2</sup>H<sub>s</sub>.V)<sup>T</sup>.(2<sup>-s/2</sup>H<sub>s</sub>) = V</p>


<p>Les fonctions de Walsh ainsi définies sont unidimensionnelles. Toute fonction de deux variables, étagée sur l'ensemble {-1, +1}, peut être développée en produits de fonctions de Walsh, 2<sup>-s</sup>W<sub>s,i</sub>W<sub>s,j</sub> (i,j = 1, 2, ..., 2<sup>s</sup>). Un exemple particulièrement intéressant est celui d'une image pixélisée sur une trame 2<sup>s</sup>x2<sup>s</sup>.</p>


<p><i>Décomposition exacte d'une image en fonctions de Walsh.</i></p>

<p>La manière la plus commode de représenter les fonctions de Walsh à deux dimensions consiste à afficher l'image Noir & Blanc de leur trame. Par exemple, dans le cas, s = 3, les 2<sup>2s</sup> (= 64) fonctions, W<sub>s,i</sub>W<sub>s,j</sub>, présentent les trames suivantes :</p>

<div><img src="annexes/walsh/walsh7.jpg" alt="" /><div class="legende">Les 64 fonctions-2D de Walsh (s = 3)</div></div>

<p>L'orthogonormalité peut être visualisée en superposant deux trames quelconques et en multipliant les valeurs pixélisées de mêmes positions (+1 si pixel blanc, -1 sinon) et en sommant sur les 64 pixels : on trouve systématiquement 0 si les trames sont distinctes et 2<sup>s</sup> (= 8) si elles sont identiques. Toute image binaire (Noire & Blanche) peut être décomposée en termes de ces fonctions de base.</p>

<p>Les images binaires qui nous servent de modèles sont celles de caractères alphabétiques, pixélisées sur une trame 64x64 (s = 6), facilement obtenables sur n'importe quel PC en suivant le protocole suivant : démarrer/exécuter/eudcedit/Sélectionner le code/OK/Edition/Copier un caractère/copier coller le caractère choisi, R par exemple, dans n'importe quel programme de dessin (Paint, par exemple). Cela donne :</p>


<div><img src="annexes/walsh/walsh5.jpg" alt="" /></div>
<p>Une représentation binaire de ce caractère qui convient pour un développement en fonctions de Walsh code les blancs par 1 et les noirs par -1. D'autres conventions sont envisageables mais celle-ci est adoptée par le logiciel Mathematica qui précise, en outre : 0 (ou tout réel inférieur) code un pixel blanc, 1 (ou tout réel supérieur) code un pixel noir et tout réel compris entre 0 et 1 code un niveau de gris.</p>

<p>Le programme Mathematica, joint en en <a href="annexes/walsh/walsh.html">annexe</a> (<a href="annexes/walsh/walsh.nb">Notebook Mathematica</a>), décompose l'image du caractère, R, en fonctions de Walsh. En soi cette décomposition semble présenter peu d'intérêt. Toutefois un point retient l'attention : les ordres de grandeur des coefficients du développement décroissent rapidement.  Voici, pour fixer les idées, le début de la liste des valeurs absolues des coefficients de Walsh correspondant à l'image de la lettre R, rangés dans l'ordre des valeurs  décroissantes :</p>

<p>{3004, 1088, 504, 500, 500, 496, 440, 436, 424, 424, 420, 420, 412, 408, 248, 248, 244, 244, 244, 240, 232, 228, 212, 208, 208, 204, 204, 200, 196, 192, 188, 188, 184, 184, 184, 180, 180, 180, 176, 176, 176, 176, 176, 172, 172, 172, 168, 164, 164, 164, 160, 160, 156, 156, 156, 152, 152, 152, 152, 152, 148, 148, 148, 144, 144, 144, 144, 140, 140, 140, 140, 140, 136, 136, 132, 128, 128, 128, 124, 124, 124, 120, 120, 116, 116, 116, 112, 112, 112, 108, 108, 108, 104, 104, 104, 104, 104, 104, 100, 100, 100, 100, 96, 92, 92, 92, 92, 92, 92, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 84, 84, 84, 84, 84, 84, 84, 84, 84, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, ...}</p>


<p>L'idée germe aussitôt de regarder ce qui se passe si on tronque le développement en série de Walsh en ne retenant que les contributions les plus importantes au-delà d'un seuil variable à définir. </p>


<p><i>Décomposition tronquée d'une image en fonctions de Walsh : compression avec perte.</i></p>

<p>Sans troncature donc sans perte, l'image reconstituée est fidèle à l'original, pixélisé de façon binaire sur {-1, +1}.  Si on tronque le développement, des valeurs intermédiaires apparaissent que Mathematica restitue en niveaux de gris, polluant plus ou moins l'image compressée. Si on conserve les 872 (sur 4096) coefficients supérieurs à 20 (en valeur absolue), voici l'image qu'on reconstitue :</p>
<div><img src="annexes/walsh/walsh8.jpg" alt="" /></div>

<p>Si on conserve les 98 (sur 4096) coefficients supérieurs à 100 (en valeur absolue), voici l'image qu'on reconstitue :</p>
<div><img src="annexes/walsh/walsh9.jpg" alt="" /></div>

<p>Si on conserve les 27 (sur 4096) coefficients supérieurs à 200 (en valeur absolue), voici l'image  qu'on reconstitue :</p>
<div><img src="annexes/walsh/walsh10.jpg" alt="" /></div>

<p>Si on supprime les niveaux de gris dans les images précédentes, on n'en garde qu'un squelette de moins en moins reconnaissable :</p>
<div><img src="annexes/walsh/walsh11.jpg" alt="" /></div>


<p>En pratique, conserver 1/16 des coefficients les plus importants (soit 256 sur 4096) suffit largement à maintenir une image nettement reconnaissable. Le taux de compression de 94% est appréciable.</p>

<p>Reste un point à élucider : il est évidemment exclu de trouver une procédure effective qui décide des indices des fonctions de Walsh à conserver dans le développement tronqué de n'importe quelle image choisie au hasard. Par contre, si on se limite à une famille de figures, par exemple l'ensemble des caractères alphabétiques occidentaux, une stratégie envisageable consiste à les recenser préalablement en répertoriant dans une base de données les indices les plus fréquents pour cette famille.</p>


<p></p>

  
  <h3>6) Machines de Turing binaires simples.</h3>
  <p>On a présenté par ailleurs sur ce site l'<a href="Tetralogique/Turing.pdf">ABC</a> des machines de Turing.  Il existe beaucoup de façons équivalentes d'en décrire le fonctionnement et nous optons pour le formalisme le plus compact, dû à Stephen Wolfram et exposé  dans son ouvrage, A New Kind of Science, en abrégé, NKS. Tous les calculs présentés en <a href="annexes/walsh/turing.html">annexe</a> (<a href="annexes/walsh/turing.nb">Notebook Mathematica</a>)  ont  été programmés en langage Mathematica en respectant un ensemble de conventions fixées par Wolfram :</p>

 <p><i>- les machines de Turing binaires simples fonctionnent sur base de k = 2 caractères (0 et 1), de s états (s = 2, 3, 4, ...) et d'une bande de lecture-écriture semi-infinie (vers la gauche) initialement uniformément peuplée de 0. La tête de lecture-écriture est  initialement positionnée à l'extrémité fixe de la bande et elle s'y trouve dans l'état, 1 (représenté, ci-dessous, par l'aiguille d'une horloge pointant sur midi);</i></p>
  
    <p><i>- la machine évolue en respectant sa table d'instructions, ne s'arrêtant que lorsque la tête est invitée à dépasser l'extrémité fixe de la bande (ci-dessous, cela revient à franchir la ligne rouge). Lorsque l'arrêt se produit, la réponse (lue de gauche à droite mais la convention inverse serait tout aussi valable) s'affiche sur la bande entre l'extrémité fixe et la position la plus extrême-gauche atteinte par la tête.</i></p>

  <p>Il existe (4s)<sup>2s</sup> machines binaires distinctes à s états, soit respectivement, 4096 (s = 2), 2985984 (s = 3), 4294967296 (s = 4), 10240000000000 (s = 5), etc. D'un point de vue logique (Tiers exclu !), toute machine s'arrête ou ne s'arrête pas et c'est bien ce qu'on observe dans les cas, s = 2, s = 3 et s = 4.  Les cas où l'arrêt se produit sont incontestables et pour les autres, l'intuition suggère l'absence d'arrêt et personne ne doute que celui-ci puisse être démontré, par exemple en travaillant par récurrence dans le cadre de l'arithmétique de Peano. Les choses se compliquent éventuellement à partir de s = 5 : outre que le nombre de cas à traiter dépasse les 4 milliards, ce qui rend l'inspection de visu problématique, la tête de certaines machines peut adopter un comportement erratique impossible à prédire.  Il est de fait bien connu que les machines de Turing sont sujettes à l'indécidabilité générique de l'arrêt même si personne ne connaît véritablement le seuil à partir duquel elle est susceptible de se manifester.  Il est illusoire de croire que l'on pourrait démontrer l'arrêt de chaque machine individuellement en travaillant dans Peano : cette arithmétique est indécidable, au sens de Gödel cette fois, ce qui signifie qu'il existe une infinité de propositions bien formulées (dont l'arrêt des machines simples de Turing) qui ne sont ni démontrables ni réfutables dans ce cadre arithmétique.</p>
  <p>L'ensemble infini mais dénombrable des machines de Turing binaires travaillant sur s états et sur une bande semi infinie, initialement peuplée de 0 (ou de 1) est universel en ce sens qu'il est susceptible d'imprimer n'importe quelle suite finie au terme de son calcul. Toutes les suites ne sont cependant pas imprimées avec des probabilités égales : à condition de trouver un moyen équitable de tirer au sort une machine de Turing à un nombre d'états quelconque, les suites courtes sont exponentiellement plus souvent imprimées que les longues.  Ceci est conforme au principe d'Ockham, présenté par ailleurs.</p>
  
  
 <p></p> 
  
  <h3>7) La machine universelle de Minsky.</h3>
<p>La plupart des machines de Turing sont dédicacées à l'exécution de tâches arithmétiques plus ou moins simples mais imposées, il existe des machines de Turing dites universelles (MTU), capables de les émuler toutes.  Ces MTU sont équivalentes entre elles et à n'importe quel ordinateur classique, pourvu d'une mémoire potentiellement infinie.</p>
<p>Cette chronique présente plus particulièrement le fonctionnement de la MTU présentée par Marvin Lee Minsky dans son livre, "Computation : Finite and Infinite Machines", un grand classique.</p>
<p><i>Notes préliminaires : La description de la machine de Minsky dans le formalisme de Wolfram figure dans NKS (page 706) mais elle est légèrement erronnée (Information et correction communiquées en privé par Matthew Szudzik, par ailleurs un temps collaborateur de Wolfram).  On trouvera ci-dessous la description présumée correcte et adaptée à la double convention que :</i></p>

<p><i>- les machines de Turing binaires simples fonctionnent sur base de k = 2 caractères (0 et 1), de s états (s = 2, 3, 4, ...) et d'une bande de lecture-écriture semi-infinie (vers la gauche) initialement uniformément peuplée de 0. Tout programme se note de droite à gauche, en base 4, à partir de l'extrémité fixe de la bande de lecture-écriture, semi-infinie vers la gauche; la tête de lecture-écriture est toujours initialement positionnée à l'extrémité fixe de la bande et elle y est dans l'état, 1 (représenté, ci-dessous, par l'aiguille d'une horloge pointant sur midi);</i></p>

<p><i>- l'arrêt de la MTU intervient lorsque cette tête   est invitée à dépasser l'extrémité fixe de la bande (ci-dessous, cela revient à franchir la ligne rouge). Lorsque l'arrêt se produit, la réponse (plus exactement son codage tel que défini par Minsky) s'affiche sur la bande à partir de la position la plus extrême-gauche atteinte par la tête jusqu'à l'extrémité fixe (entre les lignes verte et rouge dans les exemples traités ci-dessous).</i></p>

<p><i>Dans NKS, Wolfram fait état de MTU beaucoup plus simples  mais elles ne sont que &quot;faiblement&quot; universelles, nécessitant l'encodage des données initiales dans un environnement particulier (et compliqué) de la bande de lecture-écriture. En comparaison, la machine de Minsky encode le programme une bande vierge (remplie de 0).</i></p>

<div><img src="annexes/minsky/minsky1.jpg" alt="" /></div>

<p>La MTU de Minsky possède 9 états et elle travaille sur un alphabet réduit à 4 caractères notés, {0, 1, 2, 3}.  Il est facile de dresser a priori l'inventaire complet des programmes susceptibles de l'alimenter : ce sont tout simplement les suites de n caractères puisés dans l'alphabet {0, 1, 2, 3}, soit dans l'ordre naturel des valeurs croissantes de n (= 1, 2, 3, ...) :</p>
<p></p>
<p></p>
<div>{0}, {1}, {2}, {3}, {0, 0}, {0, 1}, {0, 2}, {0, 3}, {1, 0}, {1, 1}, 
{1, 2}, {1, 3}, {2, 0}, {2, 1}, {2, 2}, {2, 3}, {3, 0}, {3, 1}, {3, 
2}, {3, 3}, {0, 0, 0}, {0, 0, 1}, {0, 0, 2}, ... </div>

<p>Dans cette énumération, toute suite possède son numéro d'ordre et inversement, par exemple, {0, 0, 2} porte le numéro 23.</p>

<p>Cet inventaire est excessivement pléthorique car il ne respecte pas l'obligation d'être libre de tout préfixe (libre de tout suffixe serait plus adéquat ici vu que les programmes se lisent à l'envers) : cela signifie qu'il n'y a pas lieu de considérer un programme qui, lu de droite à gauche, commencerait comme un programme plus court dont l'arrêt est connu. Par exemple, si le programme {0, 2} s'arrête, il est inutile de considérer l'infinité des programmes qui se terminent par {0, 2}, tels {0, 0, 2} ou {3, 3, 0, 2} : les derniers caractères ne seront même pas lus. Ceci n'a rien de surprenant : dans le formalisme de Wolfram,  les programmes peuvent être aussi concis que possible et on n'a rien à faire d'un programme qui ajouterait les paroles de la Marseillaise à son corps utile. </p>
<p></p>

<div><img src="annexes/minsky/minsky4.jpg" alt="" /></div>
<p>Voici un programme naturellement (libre de tout) préfixe (on dit aussi auto-délimité) pour la machine de Minsky : il porte le numéro 250  (de droite à gauche, il se lit : {1, 1, 2, 2, ...}, peu importe ce que sont les trois points de suspension).  Il évolue exactement entre les lignes verte et rouge, ne franchissant cette dernière qu'au moment de l'arrêt,  après 11 pas, produisant la réponse 0, 0, 1, 1, lue indifféremment dans un sens ou dans l'autre. Cette ambiguïté  n'a en fait pas d'importance car la réponse affichée n'est que l'encodage (compliqué) de la véritable réponse pour laquelle la machine de Minsky est universelle au sens de Turing.  L'élucidation de cette subtilité  nécessiterait d'entrer dans le détail  du fonctionnement de la machine de Minsky, par contre, elle n'a pas d'incidence au niveau de l'arrêt.</p>
<p></p>
<p></p>
<p></p>
<p></p>

<div><img src="annexes/minsky/minsky5.jpg" alt="" /></div>
<p>Le programme n° 120 ({0, 2, 0, 3}) n'est pas (libre de tout) préfixe : certes il s'arrête mais c'est la conséquence triviale de l'arrêt du programme {2, 0, 3}. Concrètement on observe que l'évolution  de la tête n'atteint jamais la ligne verte dans ce cas. On pourrait évidemment en dire autant de tous les programmes dont l'écriture se terminerait par les symboles 2, 0 et 3.</p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>


<div><img src="annexes/minsky/minsky2.jpg" alt="" /></div>
<p>Le programme n° 313 ({3, 2, 1, 0})  s'arrête visiblement mais en empiétant sur la partie non encodée de la bande (la tête franchit la ligne verte).  Pour éviter toute ambiguïté due à des encodages différents de cette partie de la bande, le plus sûr est d'assimiler cet exemple à celui du programme {0, 3, 2, 1, 0}, portant le n° 569, quitte à considérer séparément les variantes possibles, {1, 3, 2, 1, 0}, {2, 3, 2, 1, 0} et {3, 3, 2, 1, 0}, qui pourraient parfaitement encoder des programmes qui ne  s'arrêtent pas.</p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>

<div><img src="annexes/minsky/minsky3.jpg" alt="" /></div>
<p>Le programme n° 186 ({1, 2, 1, 2}) ne s'arrête pas (dans un environnement rempli de 0 !). A ce stade, c'est l'intuition qui suggère qu'il ne s'arrête pas : si on souhaite une véritable démonstration, il faut adopter un système formel suffisamment puissant, par exemple l'arithmétique de Peano.  Dans cet exemple particulièrement simple, un raisonnement par récurrence livrerait la démonstration attendue mais d'autres cas pourraient s'avérer plus difficile.  </p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p>Le cas du programme n° 20835000109010000806 est déjà plus intrigant : s'arrête-t-il ou non , en tous cas il tourne toujours après 50 pas  ? En fait, on montre dans l'annexe qu'il s'arrête effectivement après 181 pas. Sera-ce toujours le cas ? Non, il est bien connu que le problème de l'arrêt d'une MTU  est génériquement indécidable : à côté des cas (= des programmes) pour lesquels l'arrêt est manifeste (on le constate de visu) et d'autres pour lesquels il est facile de démontrer sur la base des axiomes de l'arithmétique qu'elle ne s'arrêtera jamais, il en est une infinité d'autres pour lesquels la MTU calcule indéfiniment sans qu'on puisse prédire son évolution finale (arrêt ou non).  Les axiomes de l'arithmétique ne sont non plus d'aucun secours pour démontrer ou réfuter l'arrêt, c'est cette fois la conséquence du théorème d'incomplétude de Gödel.</p>
 
  <div><img src="annexes/minsky/minsky10.jpg" alt="" /></div>
  <p></p>
  <p>Voici le détail de l'évolution des 4 programmes de longueur 1 et des 16 programmes de longueur 2, parmi lesquels il est facile d'identifier ceux qui sont préfixes : </p>
   <div><img src="annexes/minsky/minsky8.jpg" alt="" /></div>
    <div><img src="annexes/minsky/minsky7.jpg" alt="" /></div>
    
    <p></p>
    <p>On peut poursuivre la prospection, ce qui est fait en annexe, et  identifier l'ensemble des programmes préfixes.  La quête est assuré d'être interrompue par les premiers programmes indécidables mais le fait est qu'aucun candidat ne risque de se présenter aux faibles dimensions  (bien que les caractères soient trop petits pour être distingués, les niveaux de gris suffisent à identifier les programmes évoqués, sinon se reporter à l'annexe) :</p>
    <p></p>
    
     <div><img src="annexes/minsky/minsky9.jpg" alt="" /></div>
  
  <p></p>
  

  <p>La procédure décrite construit un code des programmes préfixes permettant d'approcher par défaut le nombre <a href="Tetralogique/Godel.pdf">Omega</a> de Chaitin, défini par ailleurs (Le lecteur intéressé par les détails techniques peut se reporter à l'<a href="Tetralogique/Godel.pdf">exposé</a> présenté ailleurs sur ce site).  La convergence est comme toujours efffroyablement lente.</p>
  
  
              </div>


            <a id="ancreRetourHautPage" href="#site">&uarr;</a>

            <!-- Inclusion footer -->
            <div id="footer"></div>

        </div>
    
    
    </div>

    <script src="js/chroniques.js"></script>

</body>
</html>
